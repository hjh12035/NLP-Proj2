% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.


\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage{ACL2023}
\usepackage{CJK}
% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{listings}
\lstset{
    basicstyle=\ttfamily,
    columns=fullflexible,
    breaklines=true
}
\newcommand{\code}[1]{\lstinline!#1!}
\usepackage{graphicx}
% \usepackage[UTF8]{ctex}

\usepackage{amsmath}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}
\renewcommand{\tablename}{表格}
% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
% \usepackage{inconsolata}


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.



% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}



\begin{document}
\begin{CJK}{UTF8}{gbsn}

% TODO: 从这里开始写

\title{基于检索增强生成的智能课程助教系统}

\author{胡健豪 \\ 523031910287 \\ 第 8 组 \\\And
  姚明哲 \\ 523031910408 \\ 第 8 组 \\
}

\maketitle

\begin{abstract}
本项目实现了一个基于检索增强生成（Retrieval-Augmented Generation, RAG）技术的智能课程助教系统。
针对大语言模型在特定领域知识上的幻觉问题和时效性限制，本系统通过构建课程文档的向量知识库，实现了基于语义检索的精准问答。
系统支持PDF、PPTX、DOCX等多种格式文档的解析与切分，利用ChromaDB进行向量存储，并结合OpenAI API进行回答生成。
此外，本项目还扩展了自动习题生成和课程复习提纲生成功能，并通过React+FastAPI构建了友好的Web交互界面。
实验结果表明，该系统能有效缓解LLM的幻觉问题，提升回答的专业性和可信度。
\end{abstract}

\section{引言}
随着大语言模型的发展，AI在教育领域的应用日益广泛。
然而，直接使用通用LLM作为课程助教存在明显局限：
一是模型训练数据存在时间截止，无法获取最新的课程调整信息；
二是模型容易产生“幻觉”，生成看似合理但与课程内容不符的错误答案；
三是受限于上下文窗口，难以一次性处理大量的教材和课件。

为了解决上述问题，本项目采用了检索增强生成（RAG）技术。RAG通过在生成回答前检索外部知识库中的相关信息，将检索到的准确片段作为上下文输入给LLM，从而确保回答的准确性和可验证性。本项目旨在搭建一个智能课程助教系统，不仅能回答学生关于课程内容的提问，还能辅助生成练习题和复习提纲，为学生提供全方位的学习支持。

\section{系统设计}
整体上，系统采用“离线预处理 + 在线检索生成”的架构。
离线阶段通过 \code{process_data.py} 脚本遍历课程数据目录，对文档进行加载、切分与向量化，并写入本地 ChromaDB；
在线阶段由 RAG Agent 接收用户问题，调用向量库检索上下文，并据此构造提示词、调用 LLM 生成回答。
下面分别介绍各核心模块。

\subsection{文档处理模块}
文档处理模块由 DocumentLoader 与 TextSplitter 组成，负责从多种格式的课程资料中抽取可检索的文本块，并附带必要的位置信息（如文件名与页码）。

在 PDF 与 PPTX 场景下，将“页/幻灯片”作为自然的切分单位。
对于 PDF，\code{load_pdf} 使用 PdfReader 逐页提取文本，并统一封装为形如“\verb|--- 第 X 页 ---|”的前缀结构；
对于 PPTX，\code{load_pptx} 通过 Presentation 遍历每一张幻灯片，
对所有具备文本属性的形状进行聚合，并以“\verb|--- 幻灯片 X ---|”标记。
这样的设计一方面方便之后在回答中精确引用“第几页/第几张幻灯片”，另一方面也为后续的图片 OCR 与文本块融合提供位置对齐依据。

对于 DOCX 与 TXT 文件，其天然是线性长文本，不适合简单按页/行切分。
因而 \code{load_docx} 与 \code{load_txt} 仅负责读取完整字符串，实际的块划分则交由 TextSplitter 完成。
该类在初始化时接收 \code{chunk_size} 与 \code{chunk_overlap} 两个超参数，
分别控制每个文本块的最大长度与相邻块之间的重叠长度。

在 \code{split_text} 中，采取“窗口 + 句边界优先”的策略：
从当前起点 \code{start} 出发，先在区间 \code{[start, start + chunk_size]} 范围内确定候选片段，
再从后往前扫描句子结束符（中文的“。！？”、英文的 \verb!.!?! 以及换行符），
若能在窗口内找到合适的句末位置，则优先在此处分割；若找不到，则退化为按定长切分。
之后，新块的起点被设定为 \code{end - chunk_overlap}，
通过加入“如果没有前进至少 1 个字符则强制前进”的保护，避免在极端情况下出现死循环。

这一策略在实践中取得了两方面收益：
一是块长度在模型上下文限制之内，同时保留了足够的语义信息；
二是块之间的重叠使得跨句甚至跨段的逻辑关联得以保留，从而提高了检索结果在回答生成中的可用性。

此外，为了利用课件中的图片信息，如截图公式、流程图和板书，
DocumentLoader 还实现了 \code{extract_images_from_pdf} 和 \code{extract_images_from_pptx}。
这两个函数分别通过 \code{fitz} 与 PPTX 的图形接口枚举所有图片对象，
利用最小边长阈值过滤掉图标和装饰性小图，将剩余图片保存到 \verb|images| 目录，
然后调用 \code{pytesseract} 进行 OCR 识别。
由于零碎的无用图片过多，采取只保留字符数和词数均超过预设阈值的 OCR 文本的方式，以降低噪声。
最终，图片块也被封装为带有页码与图片 ID 的文档单元，与纯文本一同进入下游向量化流程。
Figure \ref{fig:ocr_example} 展示了检索到的图片信息是如何被模型利用的。
\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{image/ocr_example.png}
    \caption{OCR 图片内容在回答生成中的引用示例}
    \label{fig:ocr_example}
\end{figure}

\subsection{向量数据库模块}
向量数据库模块由 VectorStore 实现，其职责是将预处理后的文档块映射为向量表示，并支持基于语义相似度的检索。
选择 Chroma 作为本地持久化向量库，其 Python 接口简洁，
对元数据与 ID 管理的支持较好，便于后续做来源追踪。

在 \code{add\_documents} 中，系统对每个文档块提取 \code{content} 字段，
调用 \code{get\_embedding} 使用 Embedding 模型生成稠密向量。
考虑到换行符可能干扰 embedding 质量，在请求前将文本中的换行统一替换为空格。
每个块被分配一个唯一 ID：对于文本块使用\code{filename_p\{page\}_c\{chunk\}}，
对于图片块使用\code{filename_p\{page\}_img\{image\_id\}}，
对应的元数据中保留了文件名、文件路径、文件类型和页码等信息。
所有向量、ID、文本与元数据最终批量写入 Chroma collection 中。

为了提高检索的鲁棒性，我们在同一模块中实现了 BM25 稀疏检索。
具体而言，\code{\_tokenize} 将文本转为简单的英语单词序列（对于中文可以扩展为更合理的分词方案），
所有块的 token 列表被用于构建 \code{BM25Okapi} 模型。
向量检索通过 \code{search} 完成，BM25 则由 \code{bm25\_search} 提供。
在此基础上，实现了一个基于 Reciprocal Rank Fusion (RRF) 的混合检索接口 \code{hybrid\_search}：
分别对稠密与稀疏检索结果，按排名位置计算倒数得到得分，并对相同文档 ID 做加和排序。
该混合策略在实验中针对短问句与术语查询理论上能够表现出更好的稳定性，为后续进一步集成打下了基础。

\code{process\_data.py} 将上述流程串联起来：
检查数据目录存在性，调用 \code{DocumentLoader.load\_all\_documents} 递归加载所有支持格式的文件，
将得到的文档列表送入 \code{TextSplitter.split\_documents} 完成二次切分，
最后通过 \code{VectorStore.add\_documents} 完成整体向量索引构建。
在每次运行前，系统会清空现有 collection，以便在课程资料更新后重新构建。

\subsection{RAG智能体}
在线对话逻辑由 \code{RAGAgent} 统一管理。
该类封装了与 LLM 的交互方式、检索策略以及对话级别的状态维护。

首先，我们通过 \code{system\_prompt} 明确约束模型的“人格”和行为边界：
系统被设定为一名课程助教，需要在回答时尽量引用知识库中提供的课程资料，并在答案中说明信息来源（包括文档名与页码）；
对于不同类型的问题，如概念问答、作业/练习题、代码与实践问题等，助教应采用不同策略，
其中作业题要侧重思路和方法提示，而避免直接给出完整解答；
在交流风格上，则要求其使用中文、保持专业且友好，并适当使用苏格拉底式提问引导学生思考。

在具体问答流程中，\code{answer\_question} 首先将用户输入与对话历史传入 \code{analyze\_intent}。
借助一个轻量模型，来根据最近几轮对话分析当前问题的意图，
输出诸如 \code{NEW\_TOPIC}、\code{DRILL\_DOWN}、\code{TOPIC\_SHIFT}、
\code{CLARIFICATION}、\code{SUMMARIZATION} 或 \code{CHIT\_CHAT} 等类别，
以及一个经过消歧与补全指代的 \code{rewritten\_query}。
意图分析既可以将“这个”“它”等指代词还原为具体概念，从而提升检索准确性，
也能识别用户是否在切换话题或深入探讨某一主题，为后续的上下文窗口管理提供依据。

\code{RAGAgent} 维护了一个有限长度的上下文窗口 \code{context\_window}，该列表以最新检索到的文档片段为主，
当意图为 \code{NEW\_TOPIC} 或强烈纠正类时，窗口会被部分或全部重置；
当意图为 \code{DRILL\_DOWN} 或 \code{TOPIC\_SHIFT} 时，
则在原有窗口基础上追加新检索结果，并通过简单策略控制窗口长度与去重。
这样一来，系统在多轮对话中既能保持主题连续，又能避免无休止地扩大上下文开销。

在检索阶段，\code{retrieve\_context} 调用 \code{VectorStore} 根据重写后的查询获取若干文档片段，
并通过 \code{\_format\_context} 将它们拼接为适合填入 Prompt 的结构化文本，
其中显式包含文件名与页码，便于模型在回答中进行引用。
最终，\code{generate\_response} 将系统提示词、若干轮对话历史
以及格式化后的“课程资料 + 学生问题”作为消息列表，调用模型生成答案。
对于需要流式输出的场景，接口也预留了增量返回机制，以适配 Web 前端的实时对话体验。

\subsection{功能扩展}
在上述基础问答功能之外，我们还实现了若干与教学场景高度相关的扩展功能。

首先，在自动习题生成方面，系统提供了 \code{generate\_quiz} 接口。
用户指定主题（如“注意力机制”）、难度等级和题型（选择题或简答题），
系统会通过 \code{\_expand\_query} 使用小模型将该主题扩展为
若干更具体的检索关键词，例如加入“定义”“优点”“典型公式”等，
然后利用向量库检索覆盖面更广的上下文。
随后，我们为每一道题构造一个专用的 Prompt，要求模型在给定资料范围内生成高质量题目，
并严格按照预先约定的 JSON 格式输出题干、选项、参考答案、解析与来源信息。
题目的生成过程使用多线程并行，以加速在前端一次性展示多题的体验。

其次，在复习提纲方面，\code{generate\_outline} 支持针对“全课程”或任意子主题生成分层的 Markdown 提纲。
与习题生成类似，先通过查询扩展与检索获取与主题高度相关的多个文档片段，
再通过一个强调“层级结构、逻辑清晰与重点突出”的系统提示词，
引导模型产出使用 \#、\#\#、\#\#\# 标记的结构化内容。
前端可以基于这些 Markdown 自动渲染出树形知识结构，帮助学生从宏观上把握课程体系。
为了优化用户体验，我们在提纲生成环节采用了流式响应技术，
后端实时推送生成的 Markdown 字符，前端利用 ReactMarkdown 组件即时渲染，
大幅降低了长文本生成的首字等待时间，避免了用户在生成复杂提纲时的枯燥等待。

最后，为了提升使用的便利程度和用户体验，基于 Next.js + Tailwind CSS 实现了简单的 Web 前端，
并用 FastAPI 封装后端接口，实现了三类入口：
对话式课程助教、自动习题生成与复习提纲浏览。
对话界面采用类 ChatGPT 的流式输出方式；
习题与提纲页面则以卡片与树视图的形式展示模型输出，并保留了对应的来源信息。


\section{实验与结果展示}

为了验证系统的有效性，我们使用了“自然语言处理”课程的课件作为知识库进行了测试。
所使用的嵌入模型为 \code{text-embedding-v3}, 生成模型为 \code{qwen3-max}，轻量级意图分析模型为 \code{qwen-flash}，三者均来自于阿里云百炼的大模型api服务。

完整的问答、习题和提纲参见附录。

\subsection{问答测试}
\textbf{问题1a：} 请简述Transformer模型中的“自注意力机制” \\
\textbf{系统回答：} 如 Figure \ref{fig:1a_example} 所示

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{./image/1a.png}
    \caption{问题1a的系统回答示例}
    \label{fig:1a_example}
\end{figure}

\textbf{分析：} 系统准确描述了自注意力机制的基本原理，恰当地引用了课件中的相关内容，并提供了页码作为参考，回答符合预期。此外，界面的公式渲染清晰，提升了可读性。

\textbf{问题1b(承接问题1a)：} 深入讲解你提到的第三点 \\
\textbf{系统回答：} 如 Figure \ref{fig:1b_example} 所示

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{./image/1b.png}
    \caption{问题1b的系统回答示例}
    \label{fig:1b_example}
\end{figure}

\textbf{分析：} 系统通过轻量级模型的意图分析与问题重构的阶段，成功识别了“第三点”指代的内容————多头自注意力，在上下文中进行了有效的补全，展示了良好的多轮对话理解能力和上下文连贯性。

\textbf{问题2：} 我需要用 PyTorch 实现一个简单的词嵌入层，但不知道 embedding\_dim 参数该怎么设，能直接给我一段完整的训练代码吗？ \\
\textbf{系统回答：} 如 Figure \ref{fig:2_example} 所示

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{./image/2a.png}
    \includegraphics[width=\linewidth]{./image/2b.png}
    \caption{问题2的系统回答示例}
    \label{fig:2_example}

\end{figure}

\textbf{分析：} 系统正确理解了用户的需求，首先结合课程内容解释了 embedding\_dim 参数的选择依据，回答十分专业。而对于直接给出完整代码的要求，系统却只给出了最小可运行框架，它的回复符合系统提示词中对学术诚信的要求。

\textbf{问题3：} 请介绍一下量子计算在自然语言处理中的最新应用 \\
\textbf{系统回答：} 如 Figure \ref{fig:3_example} 所示

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{./image/3.png}
    \caption{问题3的系统回答示例}
    \label{fig:3_example}
\end{figure}
\textbf{分析：} 系统明确指出当前知识库中没有相关内容，避免了生成不准确或虚假的信息，体现了良好的信息来源追踪与查询能力，说明RAG机制有效缓解了幻觉问题。

\subsection{习题生成测试}
\textbf{输入：} n-gram 选择题 困难 2道 \\
\textbf{生成结果：} 如 Figure \ref{fig:quiz_example} 所示
\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{./image/T1.png}
    \includegraphics[width=\linewidth]{./image/T2.png}
    \caption{习题生成示例}
    \label{fig:quiz_example}
\end{figure}

\textbf{分析：} 生成的两道选择题均围绕 n-gram 的定义与应用展开，题目难度符合要求，选项设计合理，参考答案与解析十分准确，且均附带了明确的来源标注。

\subsection{复习提纲测试}
\textbf{输入主题：} 统计语言模型 \\
\textbf{生成结果：} 如 Figure \ref{fig:outline_example} 所示

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{./image/outline.png}
    \caption{复习提纲生成示例}
    \label{fig:outline_example}
\end{figure}
\textbf{分析：} 提纲结构清晰，涵盖了统计语言模型的主要内容，符合预期。



\section{总结与讨论}

围绕如何将通用大模型有效适配到具体课程场景这一问题，
我们设计并实现了一套基于检索增强生成的智能课程助教系统。
从整体架构上看，系统通过离线构建向量知识库 + 在线语义检索与生成的方式，
将课程 PDF/PPTX/DOCX 等异构资料统一映射到可检索的文本块，
并在问答阶段显式利用文件名和页码进行来源追踪，
在一定程度上缓解了通用 LLM 的幻觉问题，提升了回答的可解释性和可信度。

在系统层面，文档处理模块支持多格式课件的解析、切分与 OCR 识别，
向量数据库模块结合稠密向量检索与 BM25 稀疏检索，
为课程问答提供了较为稳健的上下文检索能力；
RAG 智能体则在此基础上实现了意图分析、对话级上下文维护以及多轮问答控制，
使系统能够在真实课堂问答和自学场景中保持较好的交互体验。
此外，自动习题生成与复习提纲生成功能表明，
同一套 RAG 基础设施可以自然扩展到多种教学辅助任务，
为后续构建更完整的智能教学助手提供了有益的实践样例。

尽管实验结果和初步使用体验显示系统具有一定实用价值，但整体上仍存在若干局限，有待进一步改进：
\begin{itemize}
    \item 多模态理解能力有限。目前系统主要依赖 OCR 将关键图片内容转写为文本，难以保留复杂公式、图表或板书的版面信息，且对低质量扫描件较为敏感。未来可以考虑引入具备文档理解能力的多模态模型，直接对 PDF 页面或截图进行整体编码，以更充分地利用视觉信息。
    \item 检索与生成耦合程度不足。现有流程中，检索阶段与生成阶段相对独立，生成模型对检索结果仅做简单拼接利用，缺乏针对候选片段的细粒度筛选与聚合。后续工作可以探索基于重排序模型的二阶段检索，或在生成过程中引入工具调用、迭代检索等机制，以提升最终回答与知识库内容的一致性。
    % \item 系统评测仍偏定性。本文主要通过案例和主观分析来评估问答质量与习题/提纲的教学价值，尚未建立统一的自动化评测基准。未来可以构建面向特定课程的小规模评测集，结合人工标注与 BLEU、ROUGE 等指标，对不同检索策略、提示词设计和模型配置进行更加系统的对比研究。
    \item 部署与成本约束。当前实现依赖云端 LLM 与 Embedding 服务，在大规模并发访问或大量离线任务的场景下，推理成本和延迟仍是落地部署需要重点考虑的问题。一条可行的方向是探索本地化或混合部署方案，引入量化后的开源模型与更高效的向量索引结构，在保证教学效果的前提下降低资源开销。
\end{itemize}

\section{成员分工}

\begin{itemize}
    \item 胡健豪：负责后端基础文档处理模块，意图分析、问题重写机制的设计与实现，后端习题与提纲生成功能的开发，
    前端Web界面搭建与API对接，与报告撰写。
    \item 姚明哲：负责后端信息检索增强和多模态识别的设计与实现，
    包括文档处理模块与向量数据库搭建，Prompt设计与优化，系统集成与测试，
    以及实验报告的撰写。
    % \item \textbf{姓名1}：负责...（例如：文档处理模块与向量数据库搭建，实验报告撰写）
    % \item \textbf{姓名2}：负责...（例如：RAG Agent核心逻辑实现，Prompt设计与优化）
    % \item \textbf{姓名3}：负责...（例如：Web前端与后端API开发，系统集成与测试）
\end{itemize}

% \bibliography{anthology,custom}
% \bibliographystyle{acl_natbib}


% \appendix

% \section{问题1完整交互记录}
% \label{app:prompt_outputs}

% \textbf{Prompt:} 请简述Transformer模型中的“自注意力机制”

% \begin{center}
% \fcolorbox{black}{gray!10}{\parbox{.9\linewidth}{

% }}
% \end{center}

\end{CJK}
\end{document}
